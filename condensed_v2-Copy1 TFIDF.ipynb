{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Set Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_requests = pd.read_excel('frc_data.xlsx', sheet_name='frc data')\n",
    "#df_requests_condensed = pd.read_excel('frc_data.xlsx', sheet_name='frc_condensed')\n",
    "# df_people = pd.read_excel('FRC Data1.xlsx', sheet_name='Requestor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Process    4010\n",
       "Systems    1975\n",
       "Forms      1587\n",
       "Rate       1235\n",
       "Other       505\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_requests['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Submission Date</th>\n",
       "      <th>Resolution Date</th>\n",
       "      <th>FRC Owner</th>\n",
       "      <th>Request</th>\n",
       "      <th>Requestor</th>\n",
       "      <th>Request Description</th>\n",
       "      <th>Status</th>\n",
       "      <th>Urgent?</th>\n",
       "      <th>Reopen?</th>\n",
       "      <th>...</th>\n",
       "      <th>Incident / PME / Project # (Where Appl.)</th>\n",
       "      <th>Created</th>\n",
       "      <th>Created By</th>\n",
       "      <th>Modified</th>\n",
       "      <th>Last Modified By</th>\n",
       "      <th>Submission Month</th>\n",
       "      <th>res date</th>\n",
       "      <th>Comments/Notes</th>\n",
       "      <th>Item Type</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14632</td>\n",
       "      <td>2018-10-18</td>\n",
       "      <td>2018-10-18</td>\n",
       "      <td>Iannacone, Kristine</td>\n",
       "      <td>Account locked in TAP</td>\n",
       "      <td>Melaniphy,Kevin M</td>\n",
       "      <td>\\n​\\nTeam,\\n \\nMy policy is locked in TAP, can...</td>\n",
       "      <td>Closed</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-10-18 16:46:51</td>\n",
       "      <td>Iannacone,Kristine</td>\n",
       "      <td>2018-10-18 17:02:04</td>\n",
       "      <td>Iannacone,Kristine</td>\n",
       "      <td>201810</td>\n",
       "      <td>10/18/2018  17:02</td>\n",
       "      <td>\\nGood afternoon Kevin,\\nThe TAP helpdesk will...</td>\n",
       "      <td>Item</td>\n",
       "      <td>ccm/FRC/Lists/TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14631</td>\n",
       "      <td>2018-10-18</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Osswald, Ernst</td>\n",
       "      <td>Can we add Tow &amp; Labor to auto without PPTs?</td>\n",
       "      <td>Loquiao,Jeffrey E</td>\n",
       "      <td>\\n​\\nHello,\\n \\nCan you please confirm if we a...</td>\n",
       "      <td>Open</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-10-18 16:42:54</td>\n",
       "      <td>Iannacone,Kristine</td>\n",
       "      <td>2018-10-18 16:42:54</td>\n",
       "      <td>Iannacone,Kristine</td>\n",
       "      <td>201810</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Item</td>\n",
       "      <td>ccm/FRC/Lists/TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14630</td>\n",
       "      <td>2018-10-18</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Ewing, Jamie</td>\n",
       "      <td>BPP rates higher than Property rates</td>\n",
       "      <td>Williams,Gina</td>\n",
       "      <td>\\n​\\nHello,\\n \\nCan you look into why the BPP ...</td>\n",
       "      <td>Open</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-10-18 16:32:44</td>\n",
       "      <td>Iannacone,Kristine</td>\n",
       "      <td>2018-10-18 16:32:44</td>\n",
       "      <td>Iannacone,Kristine</td>\n",
       "      <td>201810</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Item</td>\n",
       "      <td>ccm/FRC/Lists/TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14629</td>\n",
       "      <td>2018-10-18</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Ewing, Jamie</td>\n",
       "      <td>Problem saving files to EPC/DMF</td>\n",
       "      <td>Albright,Kevin T.</td>\n",
       "      <td>\\n​I thought I read something recently on this...</td>\n",
       "      <td>Open</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-10-18 16:25:37</td>\n",
       "      <td>Iannacone,Kristine</td>\n",
       "      <td>2018-10-18 16:25:37</td>\n",
       "      <td>Iannacone,Kristine</td>\n",
       "      <td>201810</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Item</td>\n",
       "      <td>ccm/FRC/Lists/TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14628</td>\n",
       "      <td>2018-10-18</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Iannacone, Kristine</td>\n",
       "      <td>Need point of contact for WC claims issues</td>\n",
       "      <td>Sterling,Heather</td>\n",
       "      <td>\\n​\\nHello,\\n \\nI have a insured who would lik...</td>\n",
       "      <td>Open</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-10-18 16:16:11</td>\n",
       "      <td>Iannacone,Kristine</td>\n",
       "      <td>2018-10-18 16:16:11</td>\n",
       "      <td>Iannacone,Kristine</td>\n",
       "      <td>201810</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Item</td>\n",
       "      <td>ccm/FRC/Lists/TEST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID Submission Date Resolution Date            FRC Owner  \\\n",
       "0  14632      2018-10-18      2018-10-18  Iannacone, Kristine   \n",
       "1  14631      2018-10-18             NaT       Osswald, Ernst   \n",
       "2  14630      2018-10-18             NaT         Ewing, Jamie   \n",
       "3  14629      2018-10-18             NaT         Ewing, Jamie   \n",
       "4  14628      2018-10-18             NaT  Iannacone, Kristine   \n",
       "\n",
       "                                        Request          Requestor  \\\n",
       "0                         Account locked in TAP  Melaniphy,Kevin M   \n",
       "1  Can we add Tow & Labor to auto without PPTs?  Loquiao,Jeffrey E   \n",
       "2          BPP rates higher than Property rates      Williams,Gina   \n",
       "3               Problem saving files to EPC/DMF  Albright,Kevin T.   \n",
       "4    Need point of contact for WC claims issues   Sterling,Heather   \n",
       "\n",
       "                                 Request Description  Status Urgent? Reopen?  \\\n",
       "0  \\n​\\nTeam,\\n \\nMy policy is locked in TAP, can...  Closed      No      No   \n",
       "1  \\n​\\nHello,\\n \\nCan you please confirm if we a...    Open      No      No   \n",
       "2  \\n​\\nHello,\\n \\nCan you look into why the BPP ...    Open      No      No   \n",
       "3  \\n​I thought I read something recently on this...    Open      No      No   \n",
       "4  \\n​\\nHello,\\n \\nI have a insured who would lik...    Open      No      No   \n",
       "\n",
       "          ...         Incident / PME / Project # (Where Appl.)  \\\n",
       "0         ...                                              NaN   \n",
       "1         ...                                              NaN   \n",
       "2         ...                                              NaN   \n",
       "3         ...                                              NaN   \n",
       "4         ...                                              NaN   \n",
       "\n",
       "              Created          Created By            Modified  \\\n",
       "0 2018-10-18 16:46:51  Iannacone,Kristine 2018-10-18 17:02:04   \n",
       "1 2018-10-18 16:42:54  Iannacone,Kristine 2018-10-18 16:42:54   \n",
       "2 2018-10-18 16:32:44  Iannacone,Kristine 2018-10-18 16:32:44   \n",
       "3 2018-10-18 16:25:37  Iannacone,Kristine 2018-10-18 16:25:37   \n",
       "4 2018-10-18 16:16:11  Iannacone,Kristine 2018-10-18 16:16:11   \n",
       "\n",
       "     Last Modified By Submission Month           res date  \\\n",
       "0  Iannacone,Kristine           201810  10/18/2018  17:02   \n",
       "1  Iannacone,Kristine           201810                  -   \n",
       "2  Iannacone,Kristine           201810                  -   \n",
       "3  Iannacone,Kristine           201810                  -   \n",
       "4  Iannacone,Kristine           201810                  -   \n",
       "\n",
       "                                      Comments/Notes Item Type  \\\n",
       "0  \\nGood afternoon Kevin,\\nThe TAP helpdesk will...      Item   \n",
       "1                                                NaN      Item   \n",
       "2                                                NaN      Item   \n",
       "3                                                NaN      Item   \n",
       "4                                                NaN      Item   \n",
       "\n",
       "                 Path  \n",
       "0  ccm/FRC/Lists/TEST  \n",
       "1  ccm/FRC/Lists/TEST  \n",
       "2  ccm/FRC/Lists/TEST  \n",
       "3  ccm/FRC/Lists/TEST  \n",
       "4  ccm/FRC/Lists/TEST  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_requests.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condense LOB Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "monoline_list = ['Equipment Breakdown', 'Inland Marine', 'International', 'Ocean Marine']\n",
    "package_general_liability_list = ['Connect CNP', 'General Liability', 'Multiline']\n",
    "package_property_list = ['Paramount Package', 'Property']\n",
    "condensed_lob_list = []\n",
    "for row in df_requests['LOB']:\n",
    "    if row in monoline_list:\n",
    "        condensed_lob_list.append('Monoline')\n",
    "    elif row in package_general_liability_list:\n",
    "        condensed_lob_list.append('Package General Liability')\n",
    "    elif row in package_property_list:\n",
    "        condensed_lob_list.append('Package Property')\n",
    "    else:\n",
    "        condensed_lob_list.append(row)\n",
    "        \n",
    "df_requests['Updated LOB'] = condensed_lob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Package General Liability    2407\n",
       "Auto                         1948\n",
       "Workers Comp                 1665\n",
       "Package Property             1438\n",
       "Umbrella                      878\n",
       "Not LOB Specific              561\n",
       "Monoline                      416\n",
       "Name: Updated LOB, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_requests['Updated LOB'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Classification without RST Help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_condensed = df_requests.drop(df_requests[df_requests.Channel == 'RST Help'].index)\n",
    "\n",
    "# monoline_list = ['Equipment Breakdown', 'Inland Marine', 'International', 'Ocean Marine']\n",
    "# package_general_liability_list = ['Connect CNP', 'General Liability', 'Multiline']\n",
    "# package_property_list = ['Paramount Package', 'Property']\n",
    "# condensed_lob_list = []\n",
    "# for row in df_condensed['LOB']:\n",
    "#     if row in monoline_list:\n",
    "#         condensed_lob_list.append('Monoline')\n",
    "#     elif row in package_general_liability_list:\n",
    "#         condensed_lob_list.append('Package General Liability')\n",
    "#     elif row in package_property_list:\n",
    "#         condensed_lob_list.append('Package Property')\n",
    "#     else:\n",
    "#         condensed_lob_list.append(row)\n",
    "# df_condensed['Updated LOB'] = condensed_lob_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_word_list = ['Rate Change',\n",
    "'Form Review',\n",
    "'Endorsement Print',\n",
    "'Premium Discrepancy',\n",
    "'CAT',\n",
    "'Endorsement Process',\n",
    "'Experience Modification',\n",
    "'Billing',\n",
    "'System Issue']\n",
    "condensed_list = []\n",
    "for row in df_requests['Key Word Roll-Up']:\n",
    "    if row in key_word_list:\n",
    "        condensed_list.append(row)\n",
    "    else: \n",
    "        condensed_list.append('Other')\n",
    "        \n",
    "df_requests['key_words'] = condensed_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Text Classification - LOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6705 samples, validate on 745 samples\n",
      "Epoch 1/2\n",
      "6705/6705 [==============================] - 9s 1ms/step - loss: 1.4939 - acc: 0.4786 - val_loss: 1.3127 - val_acc: 0.5557\n",
      "Epoch 2/2\n",
      "6705/6705 [==============================] - 8s 1ms/step - loss: 0.9144 - acc: 0.7028 - val_loss: 1.1748 - val_acc: 0.5799\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(df_requests) * .8)\n",
    "train_posts = df_requests['Request Description'][:train_size]\n",
    "train_tags = df_requests['Updated LOB'][:train_size]\n",
    "test_posts = df_requests['Request Description'][train_size:]\n",
    "test_tags = df_requests['Updated LOB'][train_size:]\n",
    "\n",
    "vocab_size = 1000\n",
    "tokenize = text.Tokenizer(num_words=vocab_size)\n",
    "tokenize.fit_on_texts(train_posts)\n",
    "\n",
    "x_train = tokenize.texts_to_matrix(train_posts)\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "encoder.fit(train_tags)\n",
    "y_train = encoder.transform(train_tags)\n",
    "y_test = encoder.transform(test_tags)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(512, input_shape=(vocab_size,)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(y_train.shape[1]))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, \n",
    "                    batch_size=100, \n",
    "                    epochs=2, \n",
    "                    verbose=1, \n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(x_train)\n",
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 5,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 5,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " ...]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels = [np.argmax(x) for x in predictions]\n",
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_labels = [np.argmax(x) for x in y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1498,    0,   19,   63,   20,    4,   26],\n",
       "       [  38,  137,   12,   44,   47,    2,   17],\n",
       "       [  94,    0,  287,   96,   20,    8,   36],\n",
       "       [ 242,    0,   63, 1329,  107,   26,   68],\n",
       "       [ 104,    1,   17,  148,  876,    6,   23],\n",
       "       [ 100,    0,   16,   59,   23,  420,   31],\n",
       "       [ 144,    1,   16,   69,   20,    6, 1067]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras text classification - Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6705 samples, validate on 745 samples\n",
      "Epoch 1/2\n",
      "6705/6705 [==============================] - 9s 1ms/step - loss: 1.5965 - acc: 0.4710 - val_loss: 1.4002 - val_acc: 0.5315\n",
      "Epoch 2/2\n",
      "6705/6705 [==============================] - 8s 1ms/step - loss: 1.0624 - acc: 0.6513 - val_loss: 1.1424 - val_acc: 0.5893\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(df_requests) * .8)\n",
    "train_posts = df_requests['Request'][:train_size]\n",
    "train_tags = df_requests['Updated LOB'][:train_size]\n",
    "test_posts = df_requests['Request'][train_size:]\n",
    "test_tags = df_requests['Updated LOB'][train_size:]\n",
    "\n",
    "vocab_size = 1000\n",
    "tokenize = text.Tokenizer(num_words=vocab_size)\n",
    "tokenize.fit_on_texts(train_posts)\n",
    "\n",
    "x_train = tokenize.texts_to_matrix(train_posts)\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "encoder.fit(train_tags)\n",
    "y_train = encoder.transform(train_tags)\n",
    "y_test = encoder.transform(test_tags)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(512, input_shape=(vocab_size,)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(y_train.shape[1]))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, \n",
    "                    batch_size=100, \n",
    "                    epochs=2, \n",
    "                    verbose=1, \n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N Grams - LOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/ZGS/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "sw = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9313, 14307)\n",
      "(9313, 7)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tf = TfidfVectorizer(smooth_idf=False, sublinear_tf=False, norm=None, analyzer='word')\n",
    "\n",
    "\n",
    "txt_fitted = tf.fit(df_requests['Request Description'].values.astype('U'))\n",
    "txt_transformed = txt_fitted.transform(df_requests['Request Description'].values.astype('U'))\n",
    "\n",
    "train_tags = df_requests['Updated LOB']\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "encoder.fit(train_tags)\n",
    "y_train = encoder.transform(train_tags)\n",
    "\n",
    "print(txt_transformed.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8381 samples, validate on 932 samples\n",
      "Epoch 1/10\n",
      "8381/8381 [==============================] - 141s 17ms/step - loss: 1.2210 - acc: 0.5884 - val_loss: 1.1254 - val_acc: 0.6073\n",
      "Epoch 2/10\n",
      "8381/8381 [==============================] - 140s 17ms/step - loss: 0.2931 - acc: 0.9179 - val_loss: 1.2203 - val_acc: 0.6202\n",
      "Epoch 3/10\n",
      "8381/8381 [==============================] - 145s 17ms/step - loss: 0.1219 - acc: 0.9723 - val_loss: 1.3673 - val_acc: 0.6084\n",
      "Epoch 4/10\n",
      "8381/8381 [==============================] - 143s 17ms/step - loss: 0.0623 - acc: 0.9888 - val_loss: 1.5522 - val_acc: 0.6009\n",
      "Epoch 5/10\n",
      "8381/8381 [==============================] - 139s 17ms/step - loss: 0.0376 - acc: 0.9938 - val_loss: 1.6775 - val_acc: 0.6009\n",
      "Epoch 6/10\n",
      "8381/8381 [==============================] - 159s 19ms/step - loss: 0.0266 - acc: 0.9963 - val_loss: 1.7943 - val_acc: 0.5966\n",
      "Epoch 7/10\n",
      "8381/8381 [==============================] - 140s 17ms/step - loss: 0.0205 - acc: 0.9974 - val_loss: 1.8980 - val_acc: 0.5901\n",
      "Epoch 8/10\n",
      "8381/8381 [==============================] - 139s 17ms/step - loss: 0.0166 - acc: 0.9984 - val_loss: 1.9690 - val_acc: 0.5912\n",
      "Epoch 9/10\n",
      "8381/8381 [==============================] - 137s 16ms/step - loss: 0.0134 - acc: 0.9984 - val_loss: 2.0428 - val_acc: 0.5933\n",
      "Epoch 10/10\n",
      "8381/8381 [==============================] - 135s 16ms/step - loss: 0.0132 - acc: 0.9987 - val_loss: 2.1079 - val_acc: 0.6030\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(512, input_shape=(14307,)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(7))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(txt_transformed, y_train, \n",
    "                    batch_size=100, \n",
    "                    epochs=10, \n",
    "                    verbose=1, \n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# vectorizer = CountVectorizer(stop_words=sw,ngram_range=(1,2))\n",
    "# train_posts = vectorizer.fit_transform(df_requests['Request Description'])\n",
    "# train_posts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9313, 553007)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "vectorizer = CountVectorizer(stop_words='english',ngram_range=(1,4))\n",
    "train_posts = vectorizer.fit_transform(df_requests['Request Description'].values.astype('U'))\n",
    "train_posts.shape\n",
    "#x = v.fit_transform(df['Review'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "train_size = int(len(df_requests) * .8)\n",
    "# train_posts = df_request['Request Description']#[:train_size]\n",
    "# train_tags = df_requests['Updated LOB']#[:train_size]\n",
    "# test_posts = df_requests['Request Description']#[train_size:]\n",
    "# test_tags = df_requests['Updated LOB']#[train_size:]\n",
    "# train_tags.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9313,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(len(df_requests) * .8)\n",
    "train_posts = df_requests['Request Description']#[:train_size]\n",
    "train_tags = df_requests['Updated LOB']#[:train_size]\n",
    "test_posts = df_requests['Request Description']#[train_size:]\n",
    "test_tags = df_requests['Updated LOB']#[train_size:]\n",
    "train_tags.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. ... 0. 0. 0.]\n",
      "Train on 8381 samples, validate on 932 samples\n",
      "Epoch 1/3\n",
      "8381/8381 [==============================] - 39s 5ms/step - loss: 1.3961 - acc: 0.5339 - val_loss: 1.0915 - val_acc: 0.6599\n",
      "Epoch 2/3\n",
      "8381/8381 [==============================] - 41s 5ms/step - loss: 0.7111 - acc: 0.7839 - val_loss: 1.0183 - val_acc: 0.6352\n",
      "Epoch 3/3\n",
      "8381/8381 [==============================] - 39s 5ms/step - loss: 0.4508 - acc: 0.8690 - val_loss: 1.0496 - val_acc: 0.6330\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 8000\n",
    "tokenize = text.Tokenizer(num_words=vocab_size)\n",
    "tokenize.fit_on_texts(train_posts)\n",
    "\n",
    "x_train = tokenize.texts_to_matrix(train_posts)\n",
    "#print(x_train.shape)\n",
    "\n",
    "print(x_train[0])\n",
    "encoder = LabelBinarizer()\n",
    "encoder.fit(train_tags)\n",
    "y_train = encoder.transform(train_tags)\n",
    "y_test = encoder.transform(test_tags)\n",
    "#y_train.shape\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(x_train.shape[1],)))\n",
    "#model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(y_train.shape[1]))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, \n",
    "                    batch_size=100, \n",
    "                    epochs=3, \n",
    "                    verbose=1, \n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Submission Date</th>\n",
       "      <th>Resolution Date</th>\n",
       "      <th>FRC Owner</th>\n",
       "      <th>Request</th>\n",
       "      <th>Requestor</th>\n",
       "      <th>Request Description</th>\n",
       "      <th>Status</th>\n",
       "      <th>Urgent?</th>\n",
       "      <th>Reopen?</th>\n",
       "      <th>...</th>\n",
       "      <th>Created</th>\n",
       "      <th>Created By</th>\n",
       "      <th>Modified</th>\n",
       "      <th>Last Modified By</th>\n",
       "      <th>Submission Month</th>\n",
       "      <th>res date</th>\n",
       "      <th>Comments/Notes</th>\n",
       "      <th>Item Type</th>\n",
       "      <th>Path</th>\n",
       "      <th>Updated LOB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14632</td>\n",
       "      <td>2018-10-18</td>\n",
       "      <td>2018-10-18</td>\n",
       "      <td>Iannacone, Kristine</td>\n",
       "      <td>Account locked in TAP</td>\n",
       "      <td>Melaniphy,Kevin M</td>\n",
       "      <td>\\n​\\nTeam,\\n \\nMy policy is locked in TAP, can...</td>\n",
       "      <td>Closed</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-10-18 16:46:51</td>\n",
       "      <td>Iannacone,Kristine</td>\n",
       "      <td>2018-10-18 17:02:04</td>\n",
       "      <td>Iannacone,Kristine</td>\n",
       "      <td>201810</td>\n",
       "      <td>10/18/2018  17:02</td>\n",
       "      <td>\\nGood afternoon Kevin,\\nThe TAP helpdesk will...</td>\n",
       "      <td>Item</td>\n",
       "      <td>ccm/FRC/Lists/TEST</td>\n",
       "      <td>Not LOB Specific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14631</td>\n",
       "      <td>2018-10-18</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Osswald, Ernst</td>\n",
       "      <td>Can we add Tow &amp; Labor to auto without PPTs?</td>\n",
       "      <td>Loquiao,Jeffrey E</td>\n",
       "      <td>\\n​\\nHello,\\n \\nCan you please confirm if we a...</td>\n",
       "      <td>Open</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-10-18 16:42:54</td>\n",
       "      <td>Iannacone,Kristine</td>\n",
       "      <td>2018-10-18 16:42:54</td>\n",
       "      <td>Iannacone,Kristine</td>\n",
       "      <td>201810</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Item</td>\n",
       "      <td>ccm/FRC/Lists/TEST</td>\n",
       "      <td>Auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14630</td>\n",
       "      <td>2018-10-18</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Ewing, Jamie</td>\n",
       "      <td>BPP rates higher than Property rates</td>\n",
       "      <td>Williams,Gina</td>\n",
       "      <td>\\n​\\nHello,\\n \\nCan you look into why the BPP ...</td>\n",
       "      <td>Open</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-10-18 16:32:44</td>\n",
       "      <td>Iannacone,Kristine</td>\n",
       "      <td>2018-10-18 16:32:44</td>\n",
       "      <td>Iannacone,Kristine</td>\n",
       "      <td>201810</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Item</td>\n",
       "      <td>ccm/FRC/Lists/TEST</td>\n",
       "      <td>Package Property</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14629</td>\n",
       "      <td>2018-10-18</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Ewing, Jamie</td>\n",
       "      <td>Problem saving files to EPC/DMF</td>\n",
       "      <td>Albright,Kevin T.</td>\n",
       "      <td>\\n​I thought I read something recently on this...</td>\n",
       "      <td>Open</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-10-18 16:25:37</td>\n",
       "      <td>Iannacone,Kristine</td>\n",
       "      <td>2018-10-18 16:25:37</td>\n",
       "      <td>Iannacone,Kristine</td>\n",
       "      <td>201810</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Item</td>\n",
       "      <td>ccm/FRC/Lists/TEST</td>\n",
       "      <td>Package Property</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14628</td>\n",
       "      <td>2018-10-18</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Iannacone, Kristine</td>\n",
       "      <td>Need point of contact for WC claims issues</td>\n",
       "      <td>Sterling,Heather</td>\n",
       "      <td>\\n​\\nHello,\\n \\nI have a insured who would lik...</td>\n",
       "      <td>Open</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-10-18 16:16:11</td>\n",
       "      <td>Iannacone,Kristine</td>\n",
       "      <td>2018-10-18 16:16:11</td>\n",
       "      <td>Iannacone,Kristine</td>\n",
       "      <td>201810</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Item</td>\n",
       "      <td>ccm/FRC/Lists/TEST</td>\n",
       "      <td>Workers Comp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID Submission Date Resolution Date            FRC Owner  \\\n",
       "0  14632      2018-10-18      2018-10-18  Iannacone, Kristine   \n",
       "1  14631      2018-10-18             NaT       Osswald, Ernst   \n",
       "2  14630      2018-10-18             NaT         Ewing, Jamie   \n",
       "3  14629      2018-10-18             NaT         Ewing, Jamie   \n",
       "4  14628      2018-10-18             NaT  Iannacone, Kristine   \n",
       "\n",
       "                                        Request          Requestor  \\\n",
       "0                         Account locked in TAP  Melaniphy,Kevin M   \n",
       "1  Can we add Tow & Labor to auto without PPTs?  Loquiao,Jeffrey E   \n",
       "2          BPP rates higher than Property rates      Williams,Gina   \n",
       "3               Problem saving files to EPC/DMF  Albright,Kevin T.   \n",
       "4    Need point of contact for WC claims issues   Sterling,Heather   \n",
       "\n",
       "                                 Request Description  Status Urgent? Reopen?  \\\n",
       "0  \\n​\\nTeam,\\n \\nMy policy is locked in TAP, can...  Closed      No      No   \n",
       "1  \\n​\\nHello,\\n \\nCan you please confirm if we a...    Open      No      No   \n",
       "2  \\n​\\nHello,\\n \\nCan you look into why the BPP ...    Open      No      No   \n",
       "3  \\n​I thought I read something recently on this...    Open      No      No   \n",
       "4  \\n​\\nHello,\\n \\nI have a insured who would lik...    Open      No      No   \n",
       "\n",
       "         ...                    Created          Created By  \\\n",
       "0        ...        2018-10-18 16:46:51  Iannacone,Kristine   \n",
       "1        ...        2018-10-18 16:42:54  Iannacone,Kristine   \n",
       "2        ...        2018-10-18 16:32:44  Iannacone,Kristine   \n",
       "3        ...        2018-10-18 16:25:37  Iannacone,Kristine   \n",
       "4        ...        2018-10-18 16:16:11  Iannacone,Kristine   \n",
       "\n",
       "             Modified    Last Modified By Submission Month           res date  \\\n",
       "0 2018-10-18 17:02:04  Iannacone,Kristine           201810  10/18/2018  17:02   \n",
       "1 2018-10-18 16:42:54  Iannacone,Kristine           201810                  -   \n",
       "2 2018-10-18 16:32:44  Iannacone,Kristine           201810                  -   \n",
       "3 2018-10-18 16:25:37  Iannacone,Kristine           201810                  -   \n",
       "4 2018-10-18 16:16:11  Iannacone,Kristine           201810                  -   \n",
       "\n",
       "                                      Comments/Notes Item Type  \\\n",
       "0  \\nGood afternoon Kevin,\\nThe TAP helpdesk will...      Item   \n",
       "1                                                NaN      Item   \n",
       "2                                                NaN      Item   \n",
       "3                                                NaN      Item   \n",
       "4                                                NaN      Item   \n",
       "\n",
       "                 Path       Updated LOB  \n",
       "0  ccm/FRC/Lists/TEST  Not LOB Specific  \n",
       "1  ccm/FRC/Lists/TEST              Auto  \n",
       "2  ccm/FRC/Lists/TEST  Package Property  \n",
       "3  ccm/FRC/Lists/TEST  Package Property  \n",
       "4  ccm/FRC/Lists/TEST      Workers Comp  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_requests.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('categories_output.xlsx')\n",
    "df_list.to_excel(writer,'Sheet1')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_text = []\n",
    "for row in df_requests['Updated LOB']:\n",
    "    if row == 'Package General Liability':\n",
    "        #fast_text.append('__label__Package-General-Liability')\n",
    "        fast_text.append('__label__Package-General-Liability')\n",
    "    elif row == 'Auto':\n",
    "        fast_text.append('__label__Auto')\n",
    "    elif row == 'Workers Comp':\n",
    "        fast_text.append('__label__Workers-Comp')\n",
    "    elif row =='Package Property':\n",
    "        fast_text.append('__label__Package-Property')\n",
    "    elif row == 'Umbrella':\n",
    "        fast_text.append('__label__Umbrella')\n",
    "    elif row == 'Not LOB Specific':\n",
    "        fast_text.append('__label__Not-LOB-Specific')\n",
    "    else:\n",
    "        fast_text.append('__label__Monoline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_requests['Fast Text'] = fast_text\n",
    "df_combined_text = df_requests[['Fast Text', 'Request Description']].apply(lambda x: ' '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_combined_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
